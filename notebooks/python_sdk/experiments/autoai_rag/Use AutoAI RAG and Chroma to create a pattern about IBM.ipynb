{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use AutoAI RAG and Chroma to create a pattern and get information from `ibm-watsonx-ai` SDK documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains the steps and code to demonstrate the usage of IBM AutoAI RAG. The AutoAI RAG experiment conducted in this notebook uses data scraped from the `ibm-watsonx-ai` SDK documentation.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "- Create an AutoAI RAG job that will find the best RAG pattern based on provided data\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [RAG Optimizer definition](#definition)\n",
        "- [RAG Experiment run](#run)\n",
        "- [RAG Patterns comparison and testing](#comparison)\n",
        "- [Historical runs](#runs)\n",
        "- [Clean up](#cleanup)\n",
        "- [Summary and next steps](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install and import the required modules and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U 'ibm-watsonx-ai[rag]>=1.3.26' | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the watsonx.ai credentials\n",
        "This cell defines the credentials required to work with the watsonx.ai Runtime service.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with spaces\n",
        "\n",
        "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
        "\n",
        "- Click **New Deployment Space**\n",
        "- Create an empty space\n",
        "- Select Cloud Object Storage\n",
        "- Select watsonx.ai Runtime instance and press **Create**\n",
        "- Go to **Manage** tab\n",
        "- Copy `Space GUID` into your env file or else enter it in the window which will show up after running below cell\n",
        "\n",
        "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
        "\n",
        "**Action**: assign space ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    space_id = os.environ[\"SPACE_ID\"]\n",
        "except KeyError:\n",
        "    space_id = input(\"Please enter your space_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an instance of APIClient with authentication details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials=credentials, space_id=space_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"definition\"></a>\n",
        "\n",
        "## RAG Optimizer definition\n",
        "\n",
        "### Defining a connection to training data\n",
        "\n",
        "Upload training data to a COS bucket and then define a connection to this file. This example uses the `Base` description from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) documentation.\n",
        "\n",
        "The code in the next cell uploads training data to the bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating data asset...\n",
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'68b540c6-1169-45a8-aac7-d3d1ebfe8e5f'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "url = \"https://ibm.github.io/watsonx-ai-python-sdk/base.html\"\n",
        "\n",
        "document_filename = \"base.html\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "response.raise_for_status()\n",
        "\n",
        "if not os.path.isfile(document_filename):\n",
        "    with open(document_filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "\n",
        "document_asset_details = client.data_assets.create(\n",
        "    name=document_filename, file_path=document_filename\n",
        ")\n",
        "\n",
        "document_asset_id = client.data_assets.get_id(document_asset_details)\n",
        "document_asset_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a connection to training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.helpers import DataConnection\n",
        "\n",
        "input_data_references = [DataConnection(data_asset_id=document_asset_id)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining a connection to test data\n",
        "\n",
        "Upload a `json` file that will be used for benchmarking to COS and then define a connection to this file. This example uses content from the [`ibm_watsonx_ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) SDK documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "benchmarking_data_IBM_page_content = [\n",
        "    {\n",
        "        \"question\": \"How can you set or refresh user request headers using the APIClient class?\",\n",
        "        \"correct_answer\": \"client.set_headers({'Authorization': 'Bearer <token>'})\",\n",
        "        \"correct_answer_document_ids\": [\"base.html\"],\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How to initialise Credentials object with api_key\",\n",
        "        \"correct_answer\": \"credentials = Credentials(url = 'https://us-south.ml.cloud.ibm.com', api_key = '***********')\",\n",
        "        \"correct_answer_document_ids\": [\"base.html\"],\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code in the next cell uploads testing data to the bucket as a `json` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating data asset...\n",
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'56411113-3ce3-44b8-b8ab-2d949c069496'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_filename = \"benchmarking_data_Base.json\"\n",
        "\n",
        "if not os.path.isfile(test_filename):\n",
        "    with open(test_filename, \"w\") as json_file:\n",
        "        json.dump(benchmarking_data_IBM_page_content, json_file, indent=4)\n",
        "\n",
        "test_asset_details = client.data_assets.create(\n",
        "    name=test_filename, file_path=test_filename\n",
        ")\n",
        "\n",
        "test_asset_id = client.data_assets.get_id(test_asset_details)\n",
        "test_asset_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define connection information to testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data_references = [DataConnection(data_asset_id=test_asset_id)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAG Optimizer configuration\n",
        "\n",
        "Provide the input information for AutoAI RAG optimizer:\n",
        "- `name` - experiment name\n",
        "- `description` - experiment description\n",
        "- `max_number_of_rag_patterns` - maximum number of RAG patterns to create\n",
        "- `optimization_metrics` - target optimization metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.experiment import AutoAI\n",
        "from ibm_watsonx_ai.foundation_models.schema import (\n",
        "    AutoAIRAGModelConfig,\n",
        "    AutoAIRAGRetrievalConfig,\n",
        "    AutoAIRAGLanguageConfig,\n",
        "    AutoAIRAGGenerationConfig,\n",
        ")\n",
        "\n",
        "experiment = AutoAI(\n",
        "    credentials=credentials,\n",
        "    space_id=space_id,\n",
        ")\n",
        "\n",
        "foundation_model = AutoAIRAGModelConfig(\n",
        "    model_id=\"ibm/granite-3-3-8b-instruct\",\n",
        ")\n",
        "\n",
        "language_config = AutoAIRAGLanguageConfig(\n",
        "    auto_detect=False,\n",
        ")\n",
        "\n",
        "generation_config = AutoAIRAGGenerationConfig(\n",
        "    language=language_config,\n",
        "    foundation_models=[foundation_model],\n",
        ")\n",
        "\n",
        "retrieval_config = AutoAIRAGRetrievalConfig(\n",
        "    method=\"window\",\n",
        "    number_of_chunks=5,\n",
        "    window_size=2,\n",
        ")\n",
        "\n",
        "chunking_config = {\"method\": \"recursive\", \"chunk_size\": 256, \"chunk_overlap\": 128}\n",
        "\n",
        "rag_optimizer = experiment.rag_optimizer(\n",
        "    name=\"AutoAI RAG - sample notebook\",\n",
        "    description=\"Experiment run in sample notebook\",\n",
        "    embedding_models=[\"ibm/slate-125m-english-rtrvr\", \"intfloat/multilingual-e5-large\"],\n",
        "    chunking=[chunking_config],\n",
        "    generation=generation_config,\n",
        "    retrieval=[retrieval_config],\n",
        "    max_number_of_rag_patterns=3,\n",
        "    optimization_metrics=[AutoAI.RAGMetrics.ANSWER_CORRECTNESS],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configuration parameters can be retrieved via `get_params()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'AutoAI RAG - sample notebook',\n",
              " 'description': 'Experiment run in sample notebook',\n",
              " 'chunking': [{'method': 'recursive',\n",
              "   'chunk_size': 256,\n",
              "   'chunk_overlap': 128}],\n",
              " 'embedding_models': ['ibm/slate-125m-english-rtrvr',\n",
              "  'intfloat/multilingual-e5-large'],\n",
              " 'max_number_of_rag_patterns': 3,\n",
              " 'optimization_metrics': ['answer_correctness'],\n",
              " 'generation': {'language': {'auto_detect': False},\n",
              "  'foundation_models': [{'model_id': 'ibm/granite-3-3-8b-instruct'}]},\n",
              " 'retrieval': [{'method': 'window', 'number_of_chunks': 5, 'window_size': 2}]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"run\"></a>\n",
        "## RAG Experiment run\n",
        "\n",
        "Call the `run()` method to trigger the AutoAI RAG experiment. You can either use interactive mode (synchronous job) or background mode (asynchronous job) by specifying `background_mode=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "##############################################\n",
            "\n",
            "Running '85cecb9b-1c21-4503-91a4-fc14d43ff8fa'\n",
            "\n",
            "##############################################\n",
            "\n",
            "\n",
            "pending.........\n",
            "running.........\n",
            "completed\n",
            "Training of '85cecb9b-1c21-4503-91a4-fc14d43ff8fa' finished successfully.\n"
          ]
        }
      ],
      "source": [
        "run_details = rag_optimizer.run(\n",
        "    input_data_references=input_data_references,\n",
        "    test_data_references=test_data_references,\n",
        "    background_mode=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the `get_run_status()` method to monitor AutoAI RAG jobs in background mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'completed'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.get_run_status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"comparison\"></a>\n",
        "## Comparison and testing of RAG Patterns\n",
        "\n",
        "You can list the trained patterns and information on evaluation metrics in the form of a Pandas DataFrame by calling the `summary()` method. You can use the DataFrame to compare all discovered patterns and select the one you like for further testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "   .dataframe tbody tr th:only-of-type {\n",
              "      vertical-align: middle;\n",
              "   }\n",
              "\n",
              "   .dataframe tbody tr th {\n",
              "      vertical-align: top;\n",
              "   }\n",
              "\n",
              "   .dataframe thead th {\n",
              "      text-align: right;\n",
              "   }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "   <tr style=\"text-align: right;\">\n",
              "     <th></th>\n",
              "     <th>mean_answer_correctness</th>\n",
              "     <th>mean_faithfulness</th>\n",
              "     <th>mean_context_correctness</th>\n",
              "     <th>chunking.method</th>\n",
              "     <th>chunking.chunk_size</th>\n",
              "     <th>chunking.chunk_overlap</th>\n",
              "     <th>embeddings.model_id</th>\n",
              "     <th>vector_store.distance_metric</th>\n",
              "     <th>retrieval.method</th>\n",
              "     <th>retrieval.number_of_chunks</th>\n",
              "     <th>retrieval.hybrid_ranker</th>\n",
              "     <th>generation.model_id</th>\n",
              "   </tr>\n",
              "   <tr>\n",
              "     <th>Pattern_Name</th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "   </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "   <tr>\n",
              "     <th>Pattern2</th>\n",
              "     <td>0.7083</td>\n",
              "     <td>0.2422</td>\n",
              "     <td>1.0</td>\n",
              "     <td>recursive</td>\n",
              "     <td>256</td>\n",
              "     <td>128</td>\n",
              "     <td>intfloat/multilingual-e5-large</td>\n",
              "     <td>cosine</td>\n",
              "     <td>window</td>\n",
              "     <td>5</td>\n",
              "     <td></td>\n",
              "     <td>ibm/granite-3-3-8b-instruct</td>\n",
              "   </tr>\n",
              "   <tr>\n",
              "     <th>Pattern1</th>\n",
              "     <td>0.5833</td>\n",
              "     <td>0.3195</td>\n",
              "     <td>1.0</td>\n",
              "     <td>recursive</td>\n",
              "     <td>256</td>\n",
              "     <td>128</td>\n",
              "     <td>ibm/slate-125m-english-rtrvr</td>\n",
              "     <td>cosine</td>\n",
              "     <td>window</td>\n",
              "     <td>5</td>\n",
              "     <td></td>\n",
              "     <td>ibm/granite-3-3-8b-instruct</td>\n",
              "   </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean_answer_correctness  mean_faithfulness  \\\n",
              "Pattern_Name                                    \n",
              "Pattern2                  0.7083          0.2422   \n",
              "Pattern1                  0.5833          0.3195   \n",
              "\n",
              "           mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
              "Pattern_Name                                                  \n",
              "Pattern2                     1.0      recursive              256   \n",
              "Pattern1                     1.0      recursive              256   \n",
              "\n",
              "           chunking.chunk_overlap          embeddings.model_id  \\\n",
              "Pattern_Name                                             \n",
              "Pattern2                   128  intfloat/multilingual-e5-large   \n",
              "Pattern1                   128   ibm/slate-125m-english-rtrvr   \n",
              "\n",
              "          vector_store.distance_metric retrieval.method  \\\n",
              "Pattern_Name                                     \n",
              "Pattern2                     cosine         window   \n",
              "Pattern1                     cosine         window   \n",
              "\n",
              "           retrieval.number_of_chunks retrieval.hybrid_ranker  \\\n",
              "Pattern_Name                                          \n",
              "Pattern2                        5                     \n",
              "Pattern1                        5                     \n",
              "\n",
              "                 generation.model_id  \n",
              "Pattern_Name                        \n",
              "Pattern2     ibm/granite-3-3-8b-instruct  \n",
              "Pattern1     ibm/granite-3-3-8b-instruct  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary = rag_optimizer.summary()\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additionally, you can pass the `scoring` parameter to the summary method, to filter RAG patterns starting with the best.\n",
        "\n",
        "```python\n",
        "summary = rag_optimizer.summary(scoring=\"faithfulness\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entity': {'hardware_spec': {'id': 'a6c4923b-b8e4-444c-9f43-8a7ec3020110',\n",
              "   'name': 'L'},\n",
              "  'input_data_references': [{'location': {'href': '/v2/assets/68b540c6-1169-45a8-aac7-d3d1ebfe8e5f?space_id=6f7e632c-8af4-4626-9fe2-c7128b43d32e',\n",
              "    'id': '68b540c6-1169-45a8-aac7-d3d1ebfe8e5f'},\n",
              "   'type': 'data_asset'}],\n",
              "  'parameters': {'constraints': {'chunking': [{'chunk_overlap': 128,\n",
              "     'chunk_size': 256,\n",
              "     'method': 'recursive'}],\n",
              "   'embedding_models': ['ibm/slate-125m-english-rtrvr',\n",
              "    'intfloat/multilingual-e5-large'],\n",
              "   'generation': {'foundation_models': [{'model_id': 'ibm/granite-3-3-8b-instruct'}],\n",
              "    'language': {'auto_detect': False}},\n",
              "   'max_number_of_rag_patterns': 3,\n",
              "   'retrieval': [{'method': 'window',\n",
              "     'number_of_chunks': 5,\n",
              "     'window_size': 2}]},\n",
              "   'optimization': {'metrics': ['answer_correctness']},\n",
              "   'output_logs': True},\n",
              "  'results': [{'context': {'iteration': 0,\n",
              "    'max_combinations': 2,\n",
              "    'rag_pattern': {'composition_steps': ['model_selection',\n",
              "      'chunking',\n",
              "      'embeddings',\n",
              "      'retrieval',\n",
              "      'generation'],\n",
              "     'duration_seconds': 10,\n",
              "     'location': {'evaluation_results': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern1/evaluation_results.json',\n",
              "      'indexing_notebook': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern1/indexing_inference_notebook.ipynb',\n",
              "      'inference_notebook': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern1/indexing_inference_notebook.ipynb',\n",
              "      'inference_service_code': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern1/inference_ai_service.gz',\n",
              "      'inference_service_metadata': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern1/inference_service_metadata.json'},\n",
              "     'name': 'Pattern1',\n",
              "     'settings': {'chunking': {'chunk_overlap': 128,\n",
              "      'chunk_size': 256,\n",
              "      'method': 'recursive'},\n",
              "      'embeddings': {'model_id': 'ibm/slate-125m-english-rtrvr',\n",
              "      'truncate_input_tokens': 512,\n",
              "      'truncate_strategy': 'left'},\n",
              "      'generation': {'chat_template_messages': {'system_message_text': 'You are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behaviour.',\n",
              "       'user_message_text': 'You are an AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question. \\nAnswer Length: detailed\\n{reference_documents}\\nRespond exclusively in English, regardless of the language of the question or any other language used in the provided context. Ensure that your entire response is in English only.\\n{question} \\n\\n'},\n",
              "      'context_template_text': '[Document]\\n{document}\\n[End]',\n",
              "      'model_id': 'ibm/granite-3-3-8b-instruct',\n",
              "      'parameters': {'max_completion_tokens': 1024, 'temperature': 1.0},\n",
              "      'word_to_token_ratio': 2.5035},\n",
              "      'retrieval': {'method': 'window',\n",
              "      'number_of_chunks': 5,\n",
              "      'window_size': 2},\n",
              "      'vector_store': {'datasource_type': 'chroma',\n",
              "      'distance_metric': 'cosine',\n",
              "      'index_name': 'autoai_rag_85cecb9b_20250930063141',\n",
              "      'operation': 'upsert',\n",
              "      'schema': {'fields': [{'description': 'text field',\n",
              "         'name': 'text',\n",
              "         'role': 'text',\n",
              "         'type': 'string'},\n",
              "        {'description': 'document name field',\n",
              "         'name': 'document_id',\n",
              "         'role': 'document_name',\n",
              "         'type': 'string'},\n",
              "        {'description': 'chunk starting token position in the source document',\n",
              "         'name': 'start_index',\n",
              "         'role': 'start_index',\n",
              "         'type': 'number'},\n",
              "        {'description': 'chunk number per document',\n",
              "         'name': 'sequence_number',\n",
              "         'role': 'sequence_number',\n",
              "         'type': 'number'},\n",
              "        {'description': 'vector embeddings',\n",
              "         'name': 'vector',\n",
              "         'role': 'vector_embeddings',\n",
              "         'type': 'array'}],\n",
              "       'id': 'autoai_rag_1.0',\n",
              "       'name': 'Document schema using open-source loaders',\n",
              "       'type': 'struct'}}},\n",
              "     'settings_importance': {'chunking': [{'importance': 0.125,\n",
              "       'parameter': 'chunking_method'},\n",
              "      {'importance': 0.125, 'parameter': 'chunk_overlap'},\n",
              "      {'importance': 0.125, 'parameter': 'chunk_size'}],\n",
              "      'embeddings': [{'importance': 0.125, 'parameter': 'embedding_model'}],\n",
              "      'generation': [{'importance': 0.125, 'parameter': 'foundation_model'}],\n",
              "      'retrieval': [{'importance': 0.125, 'parameter': 'retrieval_method'},\n",
              "      {'importance': 0.125, 'parameter': 'number_of_chunks'},\n",
              "      {'importance': 0.125, 'parameter': 'window_size'}]}},\n",
              "    'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
              "   'metrics': {'test_data': [{'ci_high': 0.6667,\n",
              "      'ci_low': 0.5,\n",
              "      'mean': 0.5833,\n",
              "      'metric_name': 'answer_correctness'},\n",
              "     {'ci_high': 0.3542,\n",
              "      'ci_low': 0.2848,\n",
              "      'mean': 0.3195,\n",
              "      'metric_name': 'faithfulness'},\n",
              "     {'mean': 1.0, 'metric_name': 'context_correctness'}]}},\n",
              "   {'context': {'iteration': 1,\n",
              "    'max_combinations': 2,\n",
              "    'rag_pattern': {'composition_steps': ['model_selection',\n",
              "      'chunking',\n",
              "      'embeddings',\n",
              "      'retrieval',\n",
              "      'generation'],\n",
              "     'duration_seconds': 6,\n",
              "     'location': {'evaluation_results': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern2/evaluation_results.json',\n",
              "      'indexing_notebook': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern2/indexing_inference_notebook.ipynb',\n",
              "      'inference_notebook': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern2/indexing_inference_notebook.ipynb',\n",
              "      'inference_service_code': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern2/inference_ai_service.gz',\n",
              "      'inference_service_metadata': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/Pattern2/inference_service_metadata.json'},\n",
              "     'name': 'Pattern2',\n",
              "     'settings': {'chunking': {'chunk_overlap': 128,\n",
              "      'chunk_size': 256,\n",
              "      'method': 'recursive'},\n",
              "      'embeddings': {'model_id': 'intfloat/multilingual-e5-large',\n",
              "      'truncate_input_tokens': 512,\n",
              "      'truncate_strategy': 'left'},\n",
              "      'generation': {'chat_template_messages': {'system_message_text': 'You are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behaviour.',\n",
              "       'user_message_text': 'You are an AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is grounded in context and user query. Always make sure that your response is relevant to the question. \\nAnswer Length: detailed\\n{reference_documents}\\nRespond exclusively in English, regardless of the language of the question or any other language used in the provided context. Ensure that your entire response is in English only.\\n{question} \\n\\n'},\n",
              "      'context_template_text': '[Document]\\n{document}\\n[End]',\n",
              "      'model_id': 'ibm/granite-3-3-8b-instruct',\n",
              "      'parameters': {'max_completion_tokens': 1024, 'temperature': 1.0},\n",
              "      'word_to_token_ratio': 2.5035},\n",
              "      'retrieval': {'method': 'window',\n",
              "      'number_of_chunks': 5,\n",
              "      'window_size': 2},\n",
              "      'vector_store': {'datasource_type': 'chroma',\n",
              "      'distance_metric': 'cosine',\n",
              "      'index_name': 'autoai_rag_85cecb9b_20250930063203',\n",
              "      'operation': 'upsert',\n",
              "      'schema': {'fields': [{'description': 'text field',\n",
              "         'name': 'text',\n",
              "         'role': 'text',\n",
              "         'type': 'string'},\n",
              "        {'description': 'document name field',\n",
              "         'name': 'document_id',\n",
              "         'role': 'document_name',\n",
              "         'type': 'string'},\n",
              "        {'description': 'chunk starting token position in the source document',\n",
              "         'name': 'start_index',\n",
              "         'role': 'start_index',\n",
              "         'type': 'number'},\n",
              "        {'description': 'chunk number per document',\n",
              "         'name': 'sequence_number',\n",
              "         'role': 'sequence_number',\n",
              "         'type': 'number'},\n",
              "        {'description': 'vector embeddings',\n",
              "         'name': 'vector',\n",
              "         'role': 'vector_embeddings',\n",
              "         'type': 'array'}],\n",
              "       'id': 'autoai_rag_1.0',\n",
              "       'name': 'Document schema using open-source loaders',\n",
              "       'type': 'struct'}}},\n",
              "     'settings_importance': {'chunking': [{'importance': 0.0,\n",
              "       'parameter': 'chunking_method'},\n",
              "      {'importance': 0.0, 'parameter': 'chunk_overlap'},\n",
              "      {'importance': 0.0, 'parameter': 'chunk_size'}],\n",
              "      'embeddings': [{'importance': 1.0, 'parameter': 'embedding_model'}],\n",
              "      'generation': [{'importance': 0.0, 'parameter': 'foundation_model'}],\n",
              "      'retrieval': [{'importance': 0.0, 'parameter': 'retrieval_method'},\n",
              "      {'importance': 0.0, 'parameter': 'number_of_chunks'},\n",
              "      {'importance': 0.0, 'parameter': 'window_size'}]}},\n",
              "    'software_spec': {'name': 'autoai-rag_rt24.1-py3.11'}},\n",
              "   'metrics': {'test_data': [{'ci_high': 0.75,\n",
              "      'ci_low': 0.6667,\n",
              "      'mean': 0.7083,\n",
              "      'metric_name': 'answer_correctness'},\n",
              "     {'ci_high': 0.2814,\n",
              "      'ci_low': 0.2029,\n",
              "      'mean': 0.2422,\n",
              "      'metric_name': 'faithfulness'},\n",
              "     {'mean': 1.0, 'metric_name': 'context_correctness'}]}}],\n",
              "  'results_reference': {'location': {'path': 'default_autoai_rag_out',\n",
              "   'training': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa',\n",
              "   'training_status': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/training-status.json',\n",
              "   'training_log': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/output.log',\n",
              "   'assets_path': 'default_autoai_rag_out/85cecb9b-1c21-4503-91a4-fc14d43ff8fa/assets'},\n",
              "   'type': 'container'},\n",
              "  'status': {'completed_at': '2025-09-30T06:32:25.963Z',\n",
              "   'message': {'level': 'info',\n",
              "   'text': 'AAR019I: AutoAI execution completed.'},\n",
              "   'running_at': '2025-09-30T06:31:26.000Z',\n",
              "   'state': 'completed',\n",
              "   'step': 'generation'},\n",
              "  'test_data_references': [{'location': {'href': '/v2/assets/56411113-3ce3-44b8-b8ab-2d949c069496?space_id=6f7e632c-8af4-4626-9fe2-c7128b43d32e',\n",
              "    'id': '56411113-3ce3-44b8-b8ab-2d949c069496'},\n",
              "   'type': 'data_asset'}],\n",
              "  'timestamp': '2025-09-30T06:32:29.892Z'},\n",
              " 'metadata': {'created_at': '2025-09-30T06:30:22.284Z',\n",
              "  'description': 'Experiment run in sample notebook',\n",
              "  'id': '85cecb9b-1c21-4503-91a4-fc14d43ff8fa',\n",
              "  'modified_at': '2025-09-30T06:32:26.003Z',\n",
              "  'name': 'AutoAI RAG - sample notebook',\n",
              "  'space_id': '6f7e632c-8af4-4626-9fe2-c7128b43d32e'}}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.get_run_details()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get selected pattern\n",
        "\n",
        "Get the RAGPattern object from the RAG Optimizer experiment. By default, the RAGPattern of the best pattern is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best pattern is: Pattern2\n"
          ]
        }
      ],
      "source": [
        "best_pattern_name = summary.index.values[0]\n",
        "print(\"Best pattern is:\", best_pattern_name)\n",
        "\n",
        "best_pattern = rag_optimizer.get_pattern(pattern_name=\"Pattern1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pattern details can be retrieved by calling the `get_pattern_details` method:\n",
        "\n",
        "```python\n",
        "rag_optimizer.get_pattern_details(pattern_name='Pattern2')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Query the RAGPattern locally, to test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "runtime_context = RuntimeContext(api_client=client)\n",
        "inference_service_function = best_pattern.inference_service(runtime_context)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'body': {'choices': [{'index': 0,\n",
              "   'message': {'role': 'system',\n",
              "    'content': 'To add task credentials in IBM Watsonx.ai, you would use the Credentials class. Here\\'s a general guideline on how to create and set credentials:\\n\\n1. **Using an API Key:**\\n\\n```python\\nfrom ibm_watsonx_ai import Credentials\\n\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   api_key = \\'IAM_API_KEY\\'\\n)\\n```\\n\\n2. **Using a Token:**\\n\\n```python\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   token = \"***********\"\\n)\\n```\\n\\n3. **Using Username and Password:**\\n\\n```python\\ncredentials = Credentials(\\n   url = \"<URL>\",\\n   username = \"<USERNAME>\",\\n   password = \"<PASSWORD>\",\\n   instance_id = \"openshift\"\\n)\\n```\\n\\n4. **Using Username and API Key:**\\n\\n```python\\ncredentials = Credentials(\\n   url = \"<URL>\",\\n   username = \"<USERNAME>\",\\n   api_key = IAM_API_KEY,\\n   instance_id = \"openshift\"\\n)\\n```\\n\\nOnce you have created the Credentials object, you can set it to the APIClient to perform tasks. Here\\'s a simplified version of how you might do this:\\n\\n```python\\nfrom ibm_watsonx_ai import Credentials, APIClient\\n\\n# Generating a task token.\\ntask_token = context.generate_token()\\n\\n# Creating a client with the credentials.\\nclient = APIClient(Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   token = task_token\\n))\\n\\n# Perform operations using the client.\\nresponse = client.some_operation()\\n```\\n\\nRemember, replace `<URL>`, `<USERNAME>`, `<PASSWORD>`, and `IAM_API_KEY` with your actual values. Also, ensure the URL, username, password, and API key correspond to your IBM Watsonx.ai setup.\\n\\nPlease note that the above examples don\\'t include error handling or detailed context, which might be necessary depending on your specific use case. Always ensure to handle exceptions, errors, and edge cases while using these APIs in actual applications.'},\n",
              "   'reference_documents': [{'page_content': 'bedrock_url (str, optional) – Bedrock URL, applicable for ICP only\\nproxies (dict, optional) – dictionary of proxies, containing protocol and URL mapping (example: { “https”: “https://example.url.com” }) verify (bool, optional) – certificate verification flag Example of create Credentials object\\n\\nIBM watsonx.ai for IBM Cloud\\n\\nfrom ibm_watsonx_ai import Credentials\\n\\n# Example of creating the credentials using an API key:\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   api_key = IAM_API_KEY\\n) # Example of creating the credentials using a token:\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   token = \"***********\"\\n)\\n\\n\\n\\nIBM watsonx.ai software\\n\\nimport os\\nfrom ibm_watsonx_ai import Credentials',\n",
              "     'metadata': {'sequence_number': [62, 63, 64, 65, 66],\n",
              "      'document_id': 'base.html'}},\n",
              "    {'page_content': 'Returns:\\nAPIClient which is 2-level copy of the current one, without user secrets\\n\\nReturn type:\\nAPIClient\\n\\n\\nExample:\\ndef deployable_ai_service(context, params={\"k1\":\"v1\"}, **kwargs):\\n\\n   # imports\\n   from ibm_watsonx_ai import Credentials, APIClient\\n   from ibm_watsonx_ai.foundation_models import ModelInference task_token = context.generate_token()\\n\\n   outer_context = context\\n\\n   client = APIClient(Credentials(\\n      url = \"https://us-south.ml.cloud.ibm.com\",\\n      token = task_token\\n   ))\\n\\n   # operations with client\\n\\n   def generate(context):\\n      user_client = client.get_copy()\\n      user_client.set_token(context.generate_token())\\n\\n      # operations with user_client\\n\\n      return {\\'body\\': response_body}\\n\\n   return generate\\n\\nstored_ai_service_details = client._ai_services.store(deployable_ai_service, meta_props)',\n",
              "     'metadata': {'sequence_number': [36, 37, 38, 39, 40],\n",
              "      'document_id': 'base.html'}},\n",
              "    {'page_content': 'the trusted_profile_id will be used for generating a new trusted profile token based on token passed to this method\\nuntil the client lifecycle. The generating process takes place when retrieving a token. Parameters:\\ntoken (str) – User Authorization Token\\n\\n\\nExamples\\nclient.set_token(\"<USER AUTHORIZATION TOKEN>\")\\n\\n\\n\\n\\n\\n\\nCredentials¶ class credentials.Credentials(*, url=None, api_key=None, name=None, iam_serviceid_crn=None, trusted_profile_id=None, token=None, projects_token=None, username=None, password=None, instance_id=None, version=None, bedrock_url=None, platform_url=None, proxies=None, verify=None)[source]¶ This class encapsulate passed credentials and additional params.',\n",
              "     'metadata': {'sequence_number': [49, 50, 51, 52, 53],\n",
              "      'document_id': 'base.html'}},\n",
              "    {'page_content': 'Example of create Credentials object\\n\\nIBM watsonx.ai for IBM Cloud\\n\\nfrom ibm_watsonx_ai import Credentials\\n\\n# Example of creating the credentials using an API key:\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   api_key = IAM_API_KEY\\n) # Example of creating the credentials using a token:\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   token = \"***********\"\\n)\\n\\n\\n\\nIBM watsonx.ai software\\n\\nimport os\\nfrom ibm_watsonx_ai import Credentials\\n\\n# Example of creating the credentials using username and password:\\ncredentials = Credentials(\\n   url = \"<URL>\",\\n   username = \"<USERNAME>\",\\n   password = \"<PASSWORD>\",\\n   instance_id = \"openshift\"\\n) # Example of creating the credentials using username and apikey:\\ncredentials = Credentials(\\n   url = \"<URL>\",\\n   username = \"<USERNAME>\",\\n   api_key = IAM_API_KEY,\\n   instance_id = \"openshift\"\\n)',\n",
              "     'metadata': {'sequence_number': [64, 65, 66, 67, 68],\n",
              "      'document_id': 'base.html'}},\n",
              "    {'page_content': 'class credentials.Credentials(*, url=None, api_key=None, name=None, iam_serviceid_crn=None, trusted_profile_id=None, token=None, projects_token=None, username=None, password=None, instance_id=None, version=None, bedrock_url=None, platform_url=None, proxies=None, verify=None)[source]¶ This class encapsulate passed credentials and additional params. Parameters: url (str) – URL of the service\\napi_key (str, optional) – service API key used in API key authentication\\nname (str, optional) – service name used during space creation for a Cloud environment',\n",
              "     'metadata': {'sequence_number': [51, 52, 53, 54, 55],\n",
              "      'document_id': 'base.html'}}]}]}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"How to add Task Credentials?\"\n",
        "\n",
        "context = RuntimeContext(\n",
        "    api_client=client,\n",
        "    request_payload_json={\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        ")\n",
        "\n",
        "inference_service_function(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy RAGPattern\n",
        "\n",
        "Deployment is done by storing the defined RAG function and then by creating a deployed asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: '621f18df-cb6c-49d7-84ba-83e148bf875c' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            "......\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='1d5d0cbb-3aa5-4acd-b998-c46f4b210938'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "deployment_details = best_pattern.inference_service.deploy(\n",
        "    name=\"AutoAI RAG deployment - ibm_watsonx_ai documentataion\",\n",
        "    space_id=space_id,\n",
        "    deploy_params={\"tags\": [\"wx-autoai-rag\"]},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the deployed function\n",
        "\n",
        "RAG service is now deployed in our space. To test our solution we can run the cell below. Questions have to be provided in the payload. Their format is provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)\n",
        "\n",
        "payload = {\"messages\": [{\"role\": \"user\", \"content\": question}]}\n",
        "score_response = client.deployments.run_ai_service(deployment_id, payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To add task credentials in Python while working with IBM watsonx.ai, you would use the `Credentials` class provided by the `ibm_watsonx_ai` package. This class helps encapsulate passed credentials and additional parameters. Here's an example on how you can do this:\n",
            "\n",
            "First, you need to import the necessary classes and modules:\n",
            "\n",
            "```python\n",
            "from ibm_watsonx_ai import Credentials, APIClient\n",
            "```\n",
            "\n",
            "Next, create a task token. This token is used to authenticate the client:\n",
            "\n",
            "```python\n",
            "task_token = context.generate_token()\n",
            "```\n",
            "\n",
            "Now, instantiate the `Credentials` object using the task token (or API key/token as per your use case):\n",
            "\n",
            "```python\n",
            "# Using task token\n",
            "credentials = Credentials(\n",
            "   url = \"https://us-south.ml.cloud.ibm.com\",\n",
            "   token = task_token\n",
            ")\n",
            "```\n",
            "\n",
            "Now, you can create an instance of the `APIClient` using the credentials object:\n",
            "\n",
            "```python\n",
            "client = APIClient(credentials)\n",
            "```\n",
            "\n",
            "You can create a function to encapsulate your operations with this client and handle token generation within it. Here's an example:\n",
            "\n",
            "```python\n",
            "def deployable_ai_service(context, params={\"k1\":\"v1\"}, **kwargs):\n",
            "   task_token = context.generate_token()\n",
            "\n",
            "   outer_context = context\n",
            "\n",
            "   client = APIClient(Credentials(\n",
            "      url = \"https://us-south.ml.cloud.ibm.com\",\n",
            "      token = task_token\n",
            "   ))\n",
            "\n",
            "   # operations with client\n",
            "\n",
            "   def generate(context):\n",
            "      user_client = client.get_copy()\n",
            "      user_client.set_token(context.generate_token())\n",
            "\n",
            "      # operations with user_client\n",
            "\n",
            "      return {'body': response_body}\n",
            "\n",
            "   return generate\n",
            "\n",
            "# Use the deployable_ai_service function as needed\n",
            "stored_ai_service_details = client._ai_services.store(deployable_ai_service, meta_props)\n",
            "```\n",
            "\n",
            "Note: Replace `IAM_API_KEY`, `URL`, `<USERNAME>`, `<PASSWORD>`, and `meta_props` with your actual values. The use of a token (`task_token`) or API key depends on your specific use case and security requirements.\n",
            "\n",
            "To clarify, this isn't about \"adding\" task credentials in the sense of storing or managing them somewhere. Rather, it's about initializing your client with task-specific credentials to perform operations on the IBM watsonx.ai platform. The credentials object is where you'd pass these details, allowing the client to authenticate correctly with the IBM service.\n"
          ]
        }
      ],
      "source": [
        "print(score_response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To add task credentials in Python while working with IBM watsonx.ai, you would use the `Credentials` class provided by the `ibm_watsonx_ai` package. This class helps encapsulate passed credentials and additional parameters. Here\\'s an example on how you can do this:\\n\\nFirst, you need to import the necessary classes and modules:\\n\\n```python\\nfrom ibm_watsonx_ai import Credentials, APIClient\\n```\\n\\nNext, create a task token. This token is used to authenticate the client:\\n\\n```python\\ntask_token = context.generate_token()\\n```\\n\\nNow, instantiate the `Credentials` object using the task token (or API key/token as per your use case):\\n\\n```python\\n# Using task token\\ncredentials = Credentials(\\n   url = \"https://us-south.ml.cloud.ibm.com\",\\n   token = task_token\\n)\\n```\\n\\nNow, you can create an instance of the `APIClient` using the credentials object:\\n\\n```python\\nclient = APIClient(credentials)\\n```\\n\\nYou can create a function to encapsulate your operations with this client and handle token generation within it. Here\\'s an example:\\n\\n```python\\ndef deployable_ai_service(context, params={\"k1\":\"v1\"}, **kwargs):\\n   task_token = context.generate_token()\\n\\n   outer_context = context\\n\\n   client = APIClient(Credentials(\\n      url = \"https://us-south.ml.cloud.ibm.com\",\\n      token = task_token\\n   ))\\n\\n   # operations with client\\n\\n   def generate(context):\\n      user_client = client.get_copy()\\n      user_client.set_token(context.generate_token())\\n\\n      # operations with user_client\\n\\n      return {\\'body\\': response_body}\\n\\n   return generate\\n\\n# Use the deployable_ai_service function as needed\\nstored_ai_service_details = client._ai_services.store(deployable_ai_service, meta_props)\\n```\\n\\nNote: Replace `IAM_API_KEY`, `URL`, `<USERNAME>`, `<PASSWORD>`, and `meta_props` with your actual values. The use of a token (`task_token`) or API key depends on your specific use case and security requirements.\\n\\nTo clarify, this isn\\'t about \"adding\" task credentials in the sense of storing or managing them somewhere. Rather, it\\'s about initializing your client with task-specific credentials to perform operations on the IBM watsonx.ai platform. The credentials object is where you\\'d pass these details, allowing the client to authenticate correctly with the IBM service.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_response[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"runs\"></a>\n",
        "## Historical runs\n",
        "\n",
        "In this section you learn to work with historical RAG Optimizer jobs (runs).\n",
        "\n",
        "To list historical runs use the `list()` method and provide the `'rag_optimizer'` filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment.runs(filter=\"rag_optimizer\").list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'85cecb9b-1c21-4503-91a4-fc14d43ff8fa'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_id = run_details[\"metadata\"][\"id\"]\n",
        "run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get executed optimizer's configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'AutoAI RAG - sample notebook',\n",
              " 'description': 'Experiment run in sample notebook',\n",
              " 'chunking': [{'chunk_overlap': 128,\n",
              "   'chunk_size': 256,\n",
              "   'method': 'recursive'}],\n",
              " 'embedding_models': ['ibm/slate-125m-english-rtrvr',\n",
              "  'intfloat/multilingual-e5-large'],\n",
              " 'max_number_of_rag_patterns': 3,\n",
              " 'generation': {'foundation_models': [{'model_id': 'ibm/granite-3-3-8b-instruct'}],\n",
              "  'language': {'auto_detect': False}},\n",
              " 'retrieval': [{'method': 'window', 'number_of_chunks': 5, 'window_size': 2}],\n",
              " 'optimization_metrics': ['answer_correctness']}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment.runs.get_rag_params(run_id=run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get historical rag_optimizer instance and training details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "historical_opt = experiment.runs.get_rag_optimizer(run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List trained patterns for selected optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "   .dataframe tbody tr th:only-of-type {\n",
              "      vertical-align: middle;\n",
              "   }\n",
              "\n",
              "   .dataframe tbody tr th {\n",
              "      vertical-align: top;\n",
              "   }\n",
              "\n",
              "   .dataframe thead th {\n",
              "      text-align: right;\n",
              "   }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "   <tr style=\"text-align: right;\">\n",
              "     <th></th>\n",
              "     <th>mean_answer_correctness</th>\n",
              "     <th>mean_faithfulness</th>\n",
              "     <th>mean_context_correctness</th>\n",
              "     <th>chunking.method</th>\n",
              "     <th>chunking.chunk_size</th>\n",
              "     <th>chunking.chunk_overlap</th>\n",
              "     <th>embeddings.model_id</th>\n",
              "     <th>vector_store.distance_metric</th>\n",
              "     <th>retrieval.method</th>\n",
              "     <th>retrieval.number_of_chunks</th>\n",
              "     <th>retrieval.hybrid_ranker</th>\n",
              "     <th>generation.model_id</th>\n",
              "   </tr>\n",
              "   <tr>\n",
              "     <th>Pattern_Name</th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "     <th></th>\n",
              "   </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "   <tr>\n",
              "     <th>Pattern2</th>\n",
              "     <td>0.7083</td>\n",
              "     <td>0.2422</td>\n",
              "     <td>1.0</td>\n",
              "     <td>recursive</td>\n",
              "     <td>256</td>\n",
              "     <td>128</td>\n",
              "     <td>intfloat/multilingual-e5-large</td>\n",
              "     <td>cosine</td>\n",
              "     <td>window</td>\n",
              "     <td>5</td>\n",
              "     <td></td>\n",
              "     <td>ibm/granite-3-3-8b-instruct</td>\n",
              "   </tr>\n",
              "   <tr>\n",
              "     <th>Pattern1</th>\n",
              "     <td>0.5833</td>\n",
              "     <td>0.3195</td>\n",
              "     <td>1.0</td>\n",
              "     <td>recursive</td>\n",
              "     <td>256</td>\n",
              "     <td>128</td>\n",
              "     <td>ibm/slate-125m-english-rtrvr</td>\n",
              "     <td>cosine</td>\n",
              "     <td>window</td>\n",
              "     <td>5</td>\n",
              "     <td></td>\n",
              "     <td>ibm/granite-3-3-8b-instruct</td>\n",
              "   </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean_answer_correctness  mean_faithfulness  \\\n",
              "Pattern_Name                                    \n",
              "Pattern2                  0.7083          0.2422   \n",
              "Pattern1                  0.5833          0.3195   \n",
              "\n",
              "           mean_context_correctness chunking.method  chunking.chunk_size  \\\n",
              "Pattern_Name                                                  \n",
              "Pattern2                     1.0      recursive              256   \n",
              "Pattern1                     1.0      recursive              256   \n",
              "\n",
              "           chunking.chunk_overlap          embeddings.model_id  \\\n",
              "Pattern_Name                                             \n",
              "Pattern2                   128  intfloat/multilingual-e5-large   \n",
              "Pattern1                   128   ibm/slate-125m-english-rtrvr   \n",
              "\n",
              "          vector_store.distance_metric retrieval.method  \\\n",
              "Pattern_Name                                     \n",
              "Pattern2                     cosine         window   \n",
              "Pattern1                     cosine         window   \n",
              "\n",
              "           retrieval.number_of_chunks retrieval.hybrid_ranker  \\\n",
              "Pattern_Name                                          \n",
              "Pattern2                        5                     \n",
              "Pattern1                        5                     \n",
              "\n",
              "                 generation.model_id  \n",
              "Pattern_Name                        \n",
              "Pattern2     ibm/granite-3-3-8b-instruct  \n",
              "Pattern1     ibm/granite-3-3-8b-instruct  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "historical_opt.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"cleanup\"></a>\n",
        "## Clean up\n",
        "\n",
        "To delete the current experiment, use the `cancel_run` method.\n",
        "\n",
        "**Warning:** Be careful: once you delete an experiment, you will no longer be able to refer to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_optimizer.cancel_run(hard_delete=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To delete the deployment, use the `delete` method. \n",
        "\n",
        "**Warning:** Keeping the deployment active may lead to unnecessary consumption of Compute Unit Hours (CUHs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.deployments.delete(deployment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to clean up all created assets:\n",
        "- experiments\n",
        "- trainings\n",
        "- pipelines\n",
        "- model definitions\n",
        "- models\n",
        "- functions\n",
        "- deployments\n",
        "\n",
        "please follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to use `ibm-watsonx-ai` to run AutoAI RAG experiments. \n",
        "\n",
        " Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Authors\n",
        "\n",
        "**Michał Steczko**, Software Engineer watsonx.ai\n",
        "\n",
        "Copyright © 2024-2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "notebooks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
