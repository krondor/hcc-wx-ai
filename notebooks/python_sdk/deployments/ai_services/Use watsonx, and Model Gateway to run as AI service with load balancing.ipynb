{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and Model Gateway to run as AI service with load balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for watsonx.ai Model Gateway.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The learning goal for your notebook is to leverage Model Gateway to create AI services using provided model from OpenAI compatible provider. You will also learn how to achieve model load balancing inside the AI service.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Initialize and configure Model Gateway](#gateway-configuration)\n",
        "- [Create model and deploy it as AI service](#create-model-ai-service)\n",
        "- [Create models and deploy them as an AI service with load balancing](#create-models-ai-service-load-balancing)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "- Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n",
        "\n",
        "**Note:** The example of model load balancing presented in this sample notebook may raise `Status Code 429 (Too Many Requests)` errors when using the free plan, due to lower maximum number of requests allowed per second."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install dependencies\n",
        "**Note:** `ibm-watsonx-ai` documentation can be found <a href=\"https://ibm.github.io/watsonx-ai-python-sdk/index.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed anyio-4.10.0 cachetools-6.2.0 certifi-2025.8.3 charset_normalizer-3.4.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm_watsonx_ai-1.3.40 idna-3.10 jmespath-1.0.1 lomond-0.3.3 numpy-2.3.3 pandas-2.2.3 pytz-2025.2 requests-2.32.5 sniffio-1.3.1 tabulate-0.9.0 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"ibm_watsonx_ai>=1.3.40\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the watsonx.ai credentials\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://ca-tor.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Working with spaces\n",
        "\n",
        "You need to create a space that will be used for your work. If you do not have a space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=wx) to create one.\n",
        "\n",
        "- Click **New Deployment Space**\n",
        "- Create an empty space\n",
        "- Select Cloud Object Storage\n",
        "- Select watsonx.ai Runtime instance and press **Create**\n",
        "- Go to **Manage** tab\n",
        "- Copy `Space GUID` and paste it below\n",
        "\n",
        "**Tip**: You can also use SDK to prepare the space for your work. More information can be found [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
        "\n",
        "**Action**: assign space ID below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    space_id = os.environ[\"SPACE_ID\"]\n",
        "except KeyError:\n",
        "    space_id = input(\"Please enter your space_id (hit enter): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create `APIClient` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "client = APIClient(credentials=credentials, space_id=space_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"gateway-configuration\"></a>\n",
        "## Initialize and configure Model Gateway\n",
        "In this section we will initialize the Model Gateway and configure its providers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Model Gateway\n",
        "Create `Gateway` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "gateway = Gateway(api_client=client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ID, NAME, TYPE]\n",
              "Index: []"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create secret instance in IBM Cloud Secrets Manager\n",
        "When creating a model provider, you need to supply your credentials. This is achieved by creating a key-value secret in IBM Cloud Secrets Manager and providing its CRN in the provider creation request payload.\n",
        "\n",
        "The exact specification of the secret content depends on the provider type. For more information, please see the [documentation](https://www.ibm.com/docs/en/watsonx/saas?topic=preview-setting-up-model-gateway). For watsonx.ai provider, the content should contain the following key-value pairs:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"apikey\": \"<YOUR_API_KEY>\",\n",
        "    \"auth_url\": \"https://iam.cloud.ibm.com/identity/token\",\n",
        "    \"base_url\": \"https://ca-tor.ml.cloud.ibm.com\", // You can use a different location\n",
        "    \"space_id\": \"<YOUR_SPACE_ID>\", // Required if `project_id` is not provided\n",
        "    \"project_id\": \"<YOUR_PROJECT_ID>\", // Required if `space_id` is not provided\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "secret_crn_id = \"PASTE_YOUR_SECRET_CRN_HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Work with watsonx.ai provider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c18a1610-b2fa-47bb-a986-02bceff805d8'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "watsonx_ai_provider_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\", name=\"watsonx-ai-provider\", secret_crn_id=secret_crn_id\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_id = gateway.providers.get_id(watsonx_ai_provider_details)\n",
        "watsonx_ai_provider_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get provider details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "gateway.providers.get_details(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List available models for created provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MODEL_ID</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ibm/granite-3-8b-instruct</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ibm/granite-embedding-107m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ibm/granite-embedding-278m-multilingual</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ibm/slate-125m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ibm/slate-30m-english-rtrvr-v2</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>intfloat/multilingual-e5-large</td>\n",
              "      <td>intfloat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>meta-llama/llama-3-2-11b-vision-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>meta-llama/llama-3-3-70b-instruct</td>\n",
              "      <td>Meta:Hugging Face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mistralai/mistral-large</td>\n",
              "      <td>Mistral AI:Mistral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mistralai/pixtral-12b</td>\n",
              "      <td>Mistral AI:Hugging Face</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   MODEL_ID                     TYPE\n",
              "0                 ibm/granite-3-8b-instruct                      IBM\n",
              "1   ibm/granite-embedding-107m-multilingual                      IBM\n",
              "2   ibm/granite-embedding-278m-multilingual                      IBM\n",
              "3           ibm/slate-125m-english-rtrvr-v2                      IBM\n",
              "4            ibm/slate-30m-english-rtrvr-v2                      IBM\n",
              "5            intfloat/multilingual-e5-large                 intfloat\n",
              "6  meta-llama/llama-3-2-11b-vision-instruct        Meta:Hugging Face\n",
              "7         meta-llama/llama-3-3-70b-instruct        Meta:Hugging Face\n",
              "8                   mistralai/mistral-large       Mistral AI:Mistral\n",
              "9                     mistralai/pixtral-12b  Mistral AI:Hugging Face"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list_available_models(watsonx_ai_provider_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-model-ai-service\"></a>\n",
        "\n",
        "## Create model and deploy it as AI service\n",
        "In this section we will create a model using Model Gateway and deploy it as an AI service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create model using Model Gateway\n",
        "In this sample we will use the `ibm/granite-3-8b-instruct` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = \"ibm/granite-3-8b-instruct\"\n",
        "\n",
        "model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_id,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "model_id = gateway.models.get_id(model_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>MODEL</th>\n",
              "      <th>CREATED</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65ce9f6c-0aa6-4052-b84e-87b59a59586b</td>\n",
              "      <td>ibm/granite-3-8b-instruct</td>\n",
              "      <td>2025-09-22 12:46:13</td>\n",
              "      <td>watsonxai:watsonx-ai-provider</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID  \\\n",
              "0  65ce9f6c-0aa6-4052-b84e-87b59a59586b   \n",
              "\n",
              "                                     MODEL             CREATED  \\\n",
              "0                ibm/granite-3-8b-instruct 2025-09-22 12:46:13   \n",
              "\n",
              "                                   TYPE  \n",
              "0         watsonxai:watsonx-ai-provider"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.models.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create custom software specification containing a custom version of `ibm-watsonx-ai` SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define `requirements.txt` file for package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "requirements_txt = \"ibm_watsonx_ai>=1.3.40\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the ID of base software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_software_specification_id = client.software_specifications.get_id_by_name(\n",
        "    \"runtime-24.1-py3.11\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store the package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating package extension\n",
            "SUCCESS\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.package_extensions.ConfigurationMetaNames.NAME: \"Model Gateway extension\",\n",
        "    client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Package extension with Model Gateway functionality enabled in ibm-watsonx-ai\",\n",
        "    client.package_extensions.ConfigurationMetaNames.TYPE: \"requirements_txt\",\n",
        "}\n",
        "\n",
        "package_extension_details = client.package_extensions.store(\n",
        "    meta_props, file_path=\"requirements.txt\"\n",
        ")\n",
        "package_extension_id = client.package_extensions.get_id(package_extension_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new software specification with the created package extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUCCESS\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'SUCCESS'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.software_specifications.ConfigurationMetaNames.NAME: \"Model Gateway software specification\",\n",
        "    client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification for Model Gateway\",\n",
        "    client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\n",
        "        \"guid\": base_software_specification_id\n",
        "    },\n",
        "}\n",
        "\n",
        "software_specification_details = client.software_specifications.store(meta_props)\n",
        "software_specification_id = client.software_specifications.get_id(\n",
        "    software_specification_details\n",
        ")\n",
        "\n",
        "client.software_specifications.add_package_extension(\n",
        "    software_specification_id, package_extension_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_ai_service(context, url=credentials.url, model_id=model, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_id, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_function = deployable_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"What is a tram?\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"body\": {\n",
            "    \"id\": \"chatcmpl-02cb6edd-f726-478e-83dc-cd349a0e165c---163b0e4e57a9a9f02762f431f165f083---f96564ae-b29c-406c-8d02-e208035e8c5e\",\n",
            "    \"object\": \"chat.completion\",\n",
            "    \"created\": 1758538027,\n",
            "    \"model\": \"ibm/granite-3-8b-instruct\",\n",
            "    \"choices\": [\n",
            "      {\n",
            "        \"index\": 0,\n",
            "        \"message\": {\n",
            "          \"role\": \"assistant\",\n",
            "          \"content\": \"A tram, also known as streetcar or trolley, is a rail-based public transport vehicle that operates on tracks laid in public right-of-way, usually in urban settings. Trams can be motorized or horse-drawn, but modern trams are typically electrically powered and run on dedicated lanes or shared streets. They are capable of carrying a moderate number of passengers and are often integrated into a city\\u2019s existing public transport system. Trams are distinguished from light rail vehicles (LRVs) by their higher frequency of service, shorter headways, and operation in mixed traffic, whereas light rail vehicles usually run in separated rights-of-way.\",\n",
            "          \"refusal\": \"\",\n",
            "          \"tool_calls\": null\n",
            "        },\n",
            "        \"finish_reason\": \"stop\",\n",
            "        \"logprobs\": null\n",
            "      }\n",
            "    ],\n",
            "    \"usage\": {\n",
            "      \"prompt_tokens\": 65,\n",
            "      \"completion_tokens\": 152,\n",
            "      \"total_tokens\": 217\n",
            "    },\n",
            "    \"service_tier\": null,\n",
            "    \"system_fingerprint\": \"\",\n",
            "    \"cached\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "response = local_function(context)\n",
        "print(json.dumps(response, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d0ab4ac0-347a-41b6-b392-6cff948cea57'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: 'd0ab4ac0-347a-41b6-b392-6cff948cea57' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            "......\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='c7741b7d-78f0-4fbb-b968-73afb56909a5'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Summarize core values of IBM\"\n",
        "\n",
        "deployments_results = client.deployments.run_ai_service(\n",
        "    deployment_id, {\"prompt\": question}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"cached\": false,\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"IBM's core values are encapsulated in its \\\"Values at Work\\\" program, which consists of eight distinct principles:\\n\\n1. Dedication to delivering superior value to all stakeholders\\n2. Innovation that matters for our company and our customers\\n3. Integrity by earning trust through ethical and respectful behavior\\n4. Inclusion and diversity - it's a core strength and a vital ingredient for innovation and growth\\n5. Collaboration across the enterprise to best serve our customers\\n6. Accountability for results in a results-driven culture\\n7. Empowerment to act as one, including taking calculated risks and learning from mistakes\\n8. Respect for the individual and the planet\\n\\nThese values guide the behavior and decision-making processes of IBM and its employees, promoting a strong organizational culture based on ethics, innovation, diversity, and teamwork.\",\n",
            "        \"refusal\": \"\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1758538087,\n",
            "  \"id\": \"chatcmpl-594f638d-91ed-48e3-b7c6-d38d6320c7ce---d07a82c3ca291d7a1e6be924b2aee31d---ba00df6c-d1e0-44ee-b7ef-6c71a762e035\",\n",
            "  \"model\": \"ibm/granite-3-8b-instruct\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": \"\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 192,\n",
            "    \"prompt_tokens\": 66,\n",
            "    \"total_tokens\": 258\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(deployments_results, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"create-models-ai-service-load-balancing\"></a>\n",
        "\n",
        "## Create models and deploy them as an AI service with load balancing\n",
        "In this section we will create models with the same alias using Model Gateway and deploy them as an AI service in order to perform load balancing between them.\n",
        "\n",
        "**Note:** This sample notebook creates three providers using watsonx.ai. It's worth pointing out that Model Gateway can also load balance between other providers, such as AWS Bedrock or NVIDIA NIM, as well as between different datacenters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create models using Model Gateway with the same alias on different providers\n",
        "In this sample we will use the `ibm/granite-3-8b-instruct`, `meta-llama/llama-3-2-11b-vision-instruct`, and `meta-llama/llama-3-3-70b-instruct` models in the same datacenter.\n",
        "\n",
        "**Tip:** It is also possible to perform load balancing across datacenters in different regions. In order to achieve it, when creating your providers you should use credentials for separate datacenters. See the example below:"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "watsonx_ai_provider_ca_tor_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-ca-tor\",\n",
        "    secret_crn_id=\"<secret-crn-id-for-ca-tor>\",\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_au_syd_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\",\n",
        "    name=\"watsonx-ai-provider-au-syd\",\n",
        "    secret_crn_id=\"<secret-crn-id-for-au-syd>\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_alias = \"load-balancing-models\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `ibm/granite-3-8b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "granite_3_model = \"ibm/granite-3-8b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_1_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\", name=\"watsonx-ai-provider-1\", secret_crn_id=secret_crn_id\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_1_id = gateway.providers.get_id(watsonx_ai_provider_1_details)\n",
        "\n",
        "granite_3_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_1_id, model=granite_3_model, alias=model_alias\n",
        ")\n",
        "\n",
        "granite_3_model_id = gateway.models.get_id(granite_3_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-2-11b-vision-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_2_model = \"meta-llama/llama-3-2-11b-vision-instruct\"\n",
        "\n",
        "watsonx_ai_provider_2_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\", name=\"watsonx-ai-provider-2\", secret_crn_id=secret_crn_id\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_2_id = gateway.providers.get_id(watsonx_ai_provider_2_details)\n",
        "\n",
        "llama_3_2_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_2_id, model=llama_3_2_model, alias=model_alias\n",
        ")\n",
        "\n",
        "llama_3_2_model_id = gateway.models.get_id(llama_3_2_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create provider for `meta-llama/llama-3-3-70b-instruct` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_3_3_model = \"meta-llama/llama-3-3-70b-instruct\"\n",
        "\n",
        "watsonx_ai_provider_3_details = gateway.providers.create(\n",
        "    provider=\"watsonxai\", name=\"watsonx-ai-provider-3\", secret_crn_id=secret_crn_id\n",
        ")\n",
        "\n",
        "watsonx_ai_provider_3_id = gateway.providers.get_id(watsonx_ai_provider_3_details)\n",
        "\n",
        "llama_3_3_model_details = gateway.models.create(\n",
        "    provider_id=watsonx_ai_provider_3_id, model=llama_3_3_model, alias=model_alias\n",
        ")\n",
        "\n",
        "llama_3_3_model_id = gateway.models.get_id(llama_3_3_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NAME</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c18a1610-b2fa-47bb-a986-02bceff805d8</td>\n",
              "      <td>watsonx-ai-provider</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ae732127-fd4e-4fa6-8ee3-14a385d09e63</td>\n",
              "      <td>watsonx-ai-provider-1</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1d433374-5bff-46ea-8f9d-a920fa3e214c</td>\n",
              "      <td>watsonx-ai-provider-3</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a6acebaf-0028-483a-9751-a13694b1eade</td>\n",
              "      <td>watsonx-ai-provider-2</td>\n",
              "      <td>watsonxai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID                        NAME       TYPE\n",
              "0  c18a1610-b2fa-47bb-a986-02bceff805d8         watsonx-ai-provider  watsonxai\n",
              "1  ae732127-fd4e-4fa6-8ee3-14a385d09e63       watsonx-ai-provider-1  watsonxai\n",
              "2  1d433374-5bff-46ea-8f9d-a920fa3e214c       watsonx-ai-provider-3  watsonxai\n",
              "3  a6acebaf-0028-483a-9751-a13694b1eade       watsonx-ai-provider-2  watsonxai"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.providers.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>MODEL</th>\n",
              "      <th>CREATED</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bb8a37bc-ff47-40b8-9603-95db80aae2fd</td>\n",
              "      <td>load-balancing-models</td>\n",
              "      <td>2025-09-22 12:48:42</td>\n",
              "      <td>watsonxai:watsonx-ai-provider-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ffeb2f2f-9ef3-4e3e-8b34-20c2e9e22dde</td>\n",
              "      <td>load-balancing-models</td>\n",
              "      <td>2025-09-22 12:48:33</td>\n",
              "      <td>watsonxai:watsonx-ai-provider-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10911f1f-01ce-402c-ba1e-0fb36a0dae22</td>\n",
              "      <td>load-balancing-models</td>\n",
              "      <td>2025-09-22 12:48:30</td>\n",
              "      <td>watsonxai:watsonx-ai-provider-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65ce9f6c-0aa6-4052-b84e-87b59a59586b</td>\n",
              "      <td>ibm/granite-3-8b-instruct</td>\n",
              "      <td>2025-09-22 12:46:13</td>\n",
              "      <td>watsonxai:watsonx-ai-provider</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID  \\\n",
              "0  bb8a37bc-ff47-40b8-9603-95db80aae2fd   \n",
              "1  ffeb2f2f-9ef3-4e3e-8b34-20c2e9e22dde   \n",
              "2  10911f1f-01ce-402c-ba1e-0fb36a0dae22   \n",
              "3  65ce9f6c-0aa6-4052-b84e-87b59a59586b   \n",
              "\n",
              "                                     MODEL             CREATED  \\\n",
              "0                    load-balancing-models 2025-09-22 12:48:42   \n",
              "1                    load-balancing-models 2025-09-22 12:48:33   \n",
              "2                    load-balancing-models 2025-09-22 12:48:30   \n",
              "3                ibm/granite-3-8b-instruct 2025-09-22 12:46:13   \n",
              "\n",
              "                                   TYPE  \n",
              "0       watsonxai:watsonx-ai-provider-3  \n",
              "1       watsonxai:watsonx-ai-provider-2  \n",
              "2       watsonxai:watsonx-ai-provider-1  \n",
              "3         watsonxai:watsonx-ai-provider"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gateway.models.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create AI service\n",
        "\n",
        "Prepare function which will be deployed using AI service. Please specify the default parameters that will be passed to the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deployable_load_balancing_ai_service(context, url=credentials.url, model_alias=model_alias, **kwargs): # fmt: skip\n",
        "    from ibm_watsonx_ai import APIClient, Credentials\n",
        "    from ibm_watsonx_ai.gateway import Gateway\n",
        "\n",
        "    api_client = APIClient(\n",
        "        credentials=Credentials(url=url, token=context.generate_token()),\n",
        "        space_id=context.get_space_id(),\n",
        "    )\n",
        "\n",
        "    gateway = Gateway(api_client=api_client)\n",
        "\n",
        "    def generate(context) -> dict:\n",
        "        api_client.set_token(context.get_token())\n",
        "\n",
        "        payload = context.get_json()\n",
        "        prompt = payload[\"prompt\"]\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = gateway.chat.completions.create(model=model_alias, messages=messages)\n",
        "\n",
        "        return {\"body\": response}\n",
        "\n",
        "    return generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing AI service's function locally\n",
        "\n",
        "Create AI service function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "local_load_balancing_function = deployable_load_balancing_ai_service(context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare request payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "context.request_payload_json = {\"prompt\": \"Explain what IBM is\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the function locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'ibm/granite-3-8b-instruct': 13,\n",
              "         'meta-llama/llama-3-2-11b-vision-instruct': 7,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 5})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import asyncio\n",
        "from collections import Counter\n",
        "from typing import Coroutine\n",
        "\n",
        "\n",
        "async def send_requests(function, context):\n",
        "    tasks: list[Coroutine] = []\n",
        "    for _ in range(25):\n",
        "        task = asyncio.to_thread(function, context)\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(function=local_load_balancing_function, context=context)\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"body\"][\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to Model Gateway:\n",
        "- 13 of them were handled by `ibm/granite-3-8b-instruct`,\n",
        "- 7 of them were handled by `meta-llama/llama-3-2-11b-vision-instruct`,\n",
        "- 5 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy AI service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store AI service with previously created custom software specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_props = {\n",
        "    client.repository.AIServiceMetaNames.NAME: \"Model Gateway load balancing AI service with SDK\",\n",
        "    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_specification_id,\n",
        "}\n",
        "\n",
        "stored_ai_service_details = client.repository.store_ai_service(\n",
        "    deployable_load_balancing_ai_service, meta_props\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'baaa36d4-88bf-4983-8ae3-3cbd27be4f3a'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_service_id = client.repository.get_ai_service_id(stored_ai_service_details)\n",
        "ai_service_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create online deployment of AI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "Synchronous deployment creation for id: 'baaa36d4-88bf-4983-8ae3-3cbd27be4f3a' started\n",
            "\n",
            "######################################################################################\n",
            "\n",
            "\n",
            "initializing\n",
            "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
            ".....\n",
            "ready\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Successfully finished deployment creation, deployment_id='a9571c6e-befc-4dff-9e5c-858bd47294a7'\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "meta_props = {\n",
        "    client.deployments.ConfigurationMetaNames.NAME: \"Load balancing AI service with SDK\",\n",
        "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
        "}\n",
        "\n",
        "deployment_details = client.deployments.create(ai_service_id, meta_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain the `deployment_id` of the previously created deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_id = client.deployments.get_id(deployment_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the AI service\n",
        "In the following cell there are 25 requests send to the AI service in asynchronous mode. Between each request there is a 0.2 second delay in order to avoid `429 Too Many Requests` errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'ibm/granite-3-8b-instruct': 12,\n",
              "         'meta-llama/llama-3-2-11b-vision-instruct': 10,\n",
              "         'meta-llama/llama-3-3-70b-instruct': 3})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async def send_requests(question):\n",
        "    tasks: list[Coroutine] = []\n",
        "    for _ in range(25):\n",
        "        tasks.append(\n",
        "            client.deployments.arun_ai_service(deployment_id, {\"prompt\": question})\n",
        "        )\n",
        "\n",
        "        await asyncio.sleep(0.2)\n",
        "\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "responses = await loop.create_task(\n",
        "    send_requests(question=\"Explain to me what is a dog in cat language\")\n",
        ")\n",
        "\n",
        "Counter(map(lambda x: x[\"model\"], responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As demonstrated, out of 25 requests sent to AI Service:\n",
        "- 12 of them were handled by `ibm/granite-3-8b-instruct`,\n",
        "- 10 of them were handled by `meta-llama/llama-3-2-11b-vision-instruct`,\n",
        "- 3 of them were handled by `meta-llama/llama-3-3-70b-instruct`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to create and deploy a load-balancing AI service with Model Gateway using `ibm_watsonx_ai` SDK.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Rafa Chrzanowski**, Software Engineer Intern at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright  2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
