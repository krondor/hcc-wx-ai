{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Use watsonx, and `ibm/granite-3-3-8b-instruct` to perform chat conversation with JSON response format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Disclaimers\n",
        "\n",
        "- Use only Projects and Spaces that are available in watsonx context.\n",
        "\n",
        "\n",
        "## Notebook content\n",
        "\n",
        "This notebook provides a detailed demonstration of the steps and code required to showcase support for JSON response format in Chat models.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "\n",
        "## Learning goal\n",
        "\n",
        "The purpose of this notebook is to demonstrate how to use JSON response format in Chat models and how to specify the response JSON schema.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "- [Setup](#setup)\n",
        "- [Foundation Models on watsonx](#models)\n",
        "- [Work with JSON response format](#json-response-format)\n",
        "- [Work with specified JSON schema response format](#json-specific-format)\n",
        "- [Summary](#summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Set up the environment\n",
        "\n",
        "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
        "\n",
        "-  Create a <a href=\"https://cloud.ibm.com/catalog/services/watsonxai-runtime\" target=\"_blank\" rel=\"noopener no referrer\">watsonx.ai Runtime Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install and import the `datasets` and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1A\u001b[2KSuccessfully installed anyio-4.10.0 cachetools-6.2.0 certifi-2025.8.3 charset_normalizer-3.4.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 idna-3.10 jmespath-1.0.1 lomond-0.3.3 numpy-2.3.2 pandas-2.2.3 pytz-2025.2 requests-2.32.5 sniffio-1.3.1 tabulate-0.9.0 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"ibm-watsonx-ai\" | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the watsonx.ai credentials\n",
        "Use the code cell below to define the watsonx.ai credentials that are required to work with watsonx Foundation Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">Managing user API keys</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from ibm_watsonx_ai import Credentials\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your watsonx.ai api key and hit enter: \"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define the project ID\n",
        "You need to provide the project ID to give the Foundation Model the context for the call. If you have a default project ID set in Watson Studio, the notebook obtains that project ID. Otherwise, you need to provide the project ID in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    project_id = os.environ[\"PROJECT_ID\"]\n",
        "except KeyError:\n",
        "    project_id = input(\"Enter your project_id and hit enter: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"models\"></a>\n",
        "## Set up the Foundation Model on `watsonx.ai`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the `model_id` of the model you will use for the chat with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_id = \"ibm/granite-3-3-8b-instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model parameters overview\n",
        "\n",
        "In order to receive the response from the model in the JSON format, the `TextChatResponseFormatType.JSON_OBJECT` response format must be specified. You might also need to adjust model parameters depending on the model you use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PARAMETER             | TYPE                                   | EXAMPLE VALUE                                                                                                                                                                                                                                                                   |\n",
            "+=======================+========================================+=================================================================================================================================================================================================================================================================================+\n",
            "| frequency_penalty     | float, NoneType                        | 0.5                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| logprobs              | bool, NoneType                         | True                                                                                                                                                                                                                                                                            |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| top_logprobs          | int, NoneType                          | 3                                                                                                                                                                                                                                                                               |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| presence_penalty      | float, NoneType                        | 0.3                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| response_format       | dict, TextChatResponseFormat, NoneType | {'type': 'json_schema', 'json_schema': {'name': 'Sample JSON schema', 'schema': {'title': 'SimpleUser', 'type': 'object', 'properties': {'username': {'type': 'string'}, 'email': {'type': 'string', 'format': 'email'}}, 'required': ['username', 'email']}, 'strict': False}} |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| temperature           | float, NoneType                        | 0.7                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| max_tokens            | int, NoneType                          | 100                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| max_completion_tokens | int, NoneType                          | 512                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| time_limit            | int, NoneType                          | 600000                                                                                                                                                                                                                                                                          |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| top_p                 | float, NoneType                        | 0.9                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| n                     | int, NoneType                          | 1                                                                                                                                                                                                                                                                               |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| logit_bias            | dict, NoneType                         | {'1003': -100, '1004': -100}                                                                                                                                                                                                                                                    |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| seed                  | int, NoneType                          | 41                                                                                                                                                                                                                                                                              |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| stop                  | list, NoneType                         | ['this', 'the']                                                                                                                                                                                                                                                                 |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| guided_choice         | list, NoneType                         | ['red', 'blue']                                                                                                                                                                                                                                                                 |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| guided_regex          | str, NoneType                          | \\w+@\\w+\\.xai                                                                                                                                                                                                                                                                    |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| guided_grammar        | str, NoneType                          | root ::= rating \" stars\"                                                                                                                                                                                                                                                        |\n",
            "|                       |                                        | rating ::= [1-5]                                                                                                                                                                                                                                                                |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| guided_json           | dict, NoneType                         | {'type': 'object', 'properties': {'sentiment': {'type': 'string'}}}                                                                                                                                                                                                             |\n",
            "+-----------------------+----------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
        "\n",
        "TextChatParameters.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+--------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| PARAMETER   | TYPE                                       | EXAMPLE VALUE                                                                                                                                                                                                                           |\n",
            "+=============+============================================+=========================================================================================================================================================================================================================================+\n",
            "| type        | str, TextChatResponseFormatType            | json_schema                                                                                                                                                                                                                             |\n",
            "+-------------+--------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| json_schema | dict, TextChatResponseJsonSchema, NoneType | {'name': 'Sample JSON schema', 'schema': {'title': 'SimpleUser', 'type': 'object', 'properties': {'username': {'type': 'string'}, 'email': {'type': 'string', 'format': 'email'}}, 'required': ['username', 'email']}, 'strict': False} |\n",
            "+-------------+--------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from ibm_watsonx_ai.foundation_models.schema import (\n",
        "    TextChatResponseFormat,\n",
        "    TextChatResponseFormatType,\n",
        ")\n",
        "\n",
        "TextChatResponseFormat.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"json-response-format\"></a>\n",
        "## Work with JSON response format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the model\n",
        "\n",
        "Initialize the `ModelInference` class with provided parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "\n",
        "params = TextChatParameters(\n",
        "    response_format=TextChatResponseFormat(TextChatResponseFormatType.JSON_OBJECT),\n",
        "    max_tokens=1024,\n",
        "    temperature=1,\n",
        ")\n",
        "\n",
        "model = ModelInference(\n",
        "    model_id=model_id, credentials=credentials, project_id=project_id, params=params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create messages and chat with the model\n",
        "\n",
        "In order to ensure the response is in the correct format, the sent messages must contain an indication that JSON is expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in a JSON format\"},\n",
        "    {\"role\": \"user\", \"content\": \"Describe methods of calculating pi\"},\n",
        "]\n",
        "\n",
        "chat_response = model.chat(messages=messages, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parse the response\n",
        "\n",
        "Use the `json` library to parse the chat response content into a Python-native data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"methods\": [\n",
            "    {\n",
            "      \"method\": \"Gregory-Leibniz Series\",\n",
            "      \"description\": \"This is an infinite series which alternately adds and subtracts successive terms of a harmonic sequence. It converges very slowly, so it's not practical for calculating many digits of pi. The formula is pi = 4 * (1 - 1/3 + 1/5 - 1/7 + 1/9 - ...)\"\n",
            "    },\n",
            "    {\n",
            "      \"method\": \"Nilakantha Series\",\n",
            "      \"description\": \"Also known as the Nilakantha infinite series or the Mountains and valleys series, this method converges much faster than the Gregory-Leibniz series. The formula is pi = 3 + 4/(2*3*4) - 4/(4*5*6) + 4/(6*7*8) - 4/(8*9*10) ...\"\n",
            "    },\n",
            "    {\n",
            "      \"method\": \"Machin-like formulae\",\n",
            "      \"description\": \"These formulae were discovered by John Machin and improved by others. They are—pi/4 = 4*arctan(1/5) - arctan(1/239) (the convergence here is particularly fast due to the arctan(1/239) term).\"\n",
            "    },\n",
            "    {\n",
            "      \"method\": \"Gauss-Legendre Algorithm\",\n",
            "      \"description\": \"This is an algorithm for computing π to a high precision. It's used in most modern computers for their π calculations.\"\n",
            "    },\n",
            "    {\n",
            "      \"method\": \"Ramanujan series\",\n",
            "      \"description\": \"An infinite series for π, given by Ramanujan: pi = 9801/(2 * sqrt(2) + 1) / (4096 * (n^4 * (8n^2 + 4) - (18n^4 + 8n^3 - 6n^2 - 4n + 1)))\"\n",
            "    },\n",
            "    {\n",
            "      \"method\": \"Chudnovsky algorithm\",\n",
            "      \"description\": \"This algorithm is one of the most efficient for calculating π. It is based on Ramanujan's ?, and was used in the world record calculation of π with over 22 trillion digits.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "json_response_content = json.loads(chat_response[\"choices\"][0][\"message\"][\"content\"])\n",
        "print(json.dumps(json_response_content, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"json-specific-format\"></a>\n",
        "## Work with specified JSON schema response format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the model\n",
        "\n",
        "Initialize a new `ModelInference` class with the provided parameters, including the expected JSON schema. For more info about JSON schema, visit: https://json-schema.org/learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = TextChatParameters(\n",
        "    response_format={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"Cake recipes\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"cake_name\": {\n",
        "                            \"type\": \"string\",\n",
        "                        },\n",
        "                        \"description\": {\n",
        "                            \"type\": \"string\",\n",
        "                        },\n",
        "                        \"difficulty_score\": {\n",
        "                            \"type\": \"integer\",\n",
        "                        },\n",
        "                        \"expected_price\": {\n",
        "                            \"type\": \"number\",\n",
        "                        },\n",
        "                    },\n",
        "                },\n",
        "            },\n",
        "            \"strict\": True,\n",
        "        },\n",
        "    }\n",
        ")\n",
        "\n",
        "model = ModelInference(\n",
        "    model_id=model_id, credentials=credentials, project_id=project_id, params=params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create messages and chat with the model\n",
        "\n",
        "As previously, in order to ensure the response is in the correct format, the sent message must contain an indication that JSON is expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in a JSON format.\"},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Provide a list of cake recipes. Briefly describe what the cake tastes like. Give each a difficulty score between 1-10. Also add an expected price of the cake with accuracy of 2 decimal places.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "chat_response = model.chat(messages=messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parse the response\n",
        "\n",
        "As previously, use the `json` library to parse the chat response content into a Python-native data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"cake_name\": \"Vanilla Cake\",\n",
            "    \"description\": \"Light, fluffy, and naturally sweet with a subtle vanilla flavor.\",\n",
            "    \"difficulty_score\": 3,\n",
            "    \"expected_price\": 25.99\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Chocolate Fudge Cake\",\n",
            "    \"description\": \"Rich, decadent, and deeply chocolatey with a creamy fudge center.\",\n",
            "    \"difficulty_score\": 5,\n",
            "    \"expected_price\": 32.5\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Red Velvet Cake\",\n",
            "    \"description\": \"Slightly tangy and sweet with a distinctive red color and cream cheese frosting.\",\n",
            "    \"difficulty_score\": 6,\n",
            "    \"expected_price\": 35.0\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Lemon Drizzle Cake\",\n",
            "    \"description\": \"Zesty and tangy from the lemon, balanced with a light, moist sponge.\",\n",
            "    \"difficulty_score\": 4,\n",
            "    \"expected_price\": 28.75\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Marble Cake\",\n",
            "    \"description\": \"A visually attractive cake with a swirl of choclate batter within vanilla.\",\n",
            "    \"difficulty_score\": 4,\n",
            "    \"expected_price\": 30.0\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Carrot Cake\",\n",
            "    \"description\": \"Moist cake made with grated carrots, spiced, and typically topped with cream cheese frosting.\",\n",
            "    \"difficulty_score\": 6,\n",
            "    \"expected_price\": 38.5\n",
            "  },\n",
            "  {\n",
            "    \"cake_name\": \"Cheesecake\",\n",
            "    \"description\": \"Creamy, rich, and tangy with a biscuit or oreo crumb base.\",\n",
            "    \"difficulty_score\": 7,\n",
            "    \"expected_price\": 42.0\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "json_response_content = json.loads(chat_response[\"choices\"][0][\"message\"][\"content\"])\n",
        "print(json.dumps(json_response_content, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a id=\"summary\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "You successfully completed this notebook!\n",
        "\n",
        "You learned how to work with chat models using tools and watsonx.ai.\n",
        "\n",
        "Check out our _<a href=\"https://ibm.github.io/watsonx-ai-python-sdk/samples.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a>_ for more samples, tutorials, documentation, how-tos, and blog posts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Author\n",
        "\n",
        "**Rafał Chrzanowski**, Software Engineer Intern at watsonx.ai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2025 IBM. This notebook and its source code are released under the terms of the MIT License."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watsonx-ai-samples-py-311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
